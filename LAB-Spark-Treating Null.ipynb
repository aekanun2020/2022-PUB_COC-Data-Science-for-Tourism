{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pyspark.sql import functions as sparkf\n","\n","raw_df = spark.createDataFrame(\n"," [\n","  ('Store 1',1,448),\n","  ('Store 1',2,None),\n","  ('Store 1',3,499),\n","  ('Store 1',44,432),\n","  (None,None,None),\n","  ('Store 2',1,355),\n","  ('Store 2',1,355),\n","  ('Store 2',None,345),\n","  ('Store 2',3,387),\n","  ('Store 2',4,312)\n","],\n"," ['Store','WeekInMonth','Revenue']\n",")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Store: string (nullable = true)\n"," |-- WeekInMonth: long (nullable = true)\n"," |-- Revenue: long (nullable = true)\n","\n"]}],"source":["raw_df.printSchema()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["raw_df.count()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   null|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|   null|       null|   null|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|       null|    345|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["raw_df.show()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-------+------------------+------------------+\n","|summary|  Store|       WeekInMonth|           Revenue|\n","+-------+-------+------------------+------------------+\n","|  count|      9|                 8|                 8|\n","|   mean|   null|             7.375|           391.625|\n","| stddev|   null|14.841423689890979|62.741960213469355|\n","|    min|Store 1|                 1|               312|\n","|    max|Store 2|                44|               499|\n","+-------+-------+------------------+------------------+\n","\n"]}],"source":["raw_df.describe().show()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------+-------+\n","|Store|WeekInMonth|Revenue|\n","+-----+-----------+-------+\n","|    1|          2|      2|\n","+-----+-----------+-------+\n","\n"]}],"source":["raw_df.select(\n","  [sparkf.count(sparkf.when(sparkf.isnull(c), c)).alias(c) for c in raw_df.columns]\n",").show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          2|   null|\n","|   null|       null|   null|\n","|Store 2|       null|    345|\n","+-------+-----------+-------+\n","\n"]}],"source":["#ระบุว่า Nulls อยู่ที่ row ไหน - เพื่อดูว่าเป็น MCAR / MAR / MNAR / Structural Missing\n","\n","from functools import reduce\n","\n","raw_df.filter(reduce(lambda a1, a2: a1 | a2,\\\n","                     (sparkf.col(c).isNull() \\\n","                      for c in raw_df.columns))).show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   null|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|       null|    345|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["#ซ่อน/ลบ เฉพาะ row ที่มีค่า nulls ในทุก attributes แล้วซ่อนค่า nulls จากนั้นส่งให้กับตัวแปรใหม่ [III]\n","\n","noNullRow_Df = raw_df.dropna('all')\n","\n","noNullRow_Df.show()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   null|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["#ซ่อน/ลบ row ที่มีค่า nulls ใน attributes ใด attribute หนึ่ง (หรือทุก attributes) จาก subset [IV]\n","\n","\n","raw_df.dropna(how='any', \\\n","              subset=['Store','WeekInMonth']).show()\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["#ซ่อน/ลบ row ที่มีค่า nulls ใน attributes ใด attribute หนึ่ง (หรือทุก attributes) แล้วส่งให้กับตัวแปรใหม่ [V]\n","\n","raw_df.dropna(how='any').show()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   9999|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|   null|       null|   9999|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|       null|    345|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["#แทนที่ค่า nulls ด้วยเลข 9999 เฉพาะใน “Revenue” [VI]\n","\n","raw_df.fillna(9999,['Revenue']).show()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------+-----------+-------+\n","|         Store|WeekInMonth|Revenue|\n","+--------------+-----------+-------+\n","|       Store 1|          1|    448|\n","|       Store 1|          2|      3|\n","|       Store 1|          3|    499|\n","|       Store 1|         44|    432|\n","|Assume_Store 1|          2|      3|\n","|       Store 2|          1|    355|\n","|       Store 2|          1|    355|\n","|       Store 2|          2|    345|\n","|       Store 2|          3|    387|\n","|       Store 2|          4|    312|\n","+--------------+-----------+-------+\n","\n"]}],"source":["#แทนที่ค่า nulls ด้วยเลข 0 ในทุก Attributes ซึ่งเป็น numeric และด้วยค่าอื่นๆ สำหรับ string [VII]\n","raw_df.fillna({'Store':'Assume_Store 1',\\\n","              'WeekInMonth':'2','Revenue':3}).show()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# [VIII]\n","from pyspark.sql import functions as sparkf"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   null|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|   null|       null|   null|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|       null|    345|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["raw_df.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Store: string (nullable = true)\n"," |-- WeekInMonth: long (nullable = true)\n"," |-- Revenue: long (nullable = true)\n","\n"]}],"source":["raw_df.printSchema()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["magic_percentile = sparkf.expr('percentile_approx(Revenue, 0.5)')"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 2|          4|    312|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|          3|    387|\n","|Store 1|         44|    432|\n","|Store 1|          1|    448|\n","|Store 1|          3|    499|\n","+-------+-----------+-------+\n","\n"]}],"source":["raw_df.na.drop().orderBy('Revenue').show()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-------+\n","|  Store|med_val|\n","+-------+-------+\n","|Store 1|    448|\n","+-------+-------+\n","\n"]}],"source":["raw_df.na.drop().groupBy('Store').agg(magic_percentile.alias('med_val'))\\\n",".filter(sparkf.col('Store') == 'Store 1').show()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["imputed_value = raw_df.na.drop().groupBy('Store').agg(magic_percentile.alias('med_val'))\\\n",".filter(sparkf.col('Store') == 'Store 1').collect()[0][1]"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["448"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["imputed_value"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+--------------+\n","|  Store|WeekInMonth|Revenue|noNull_Revenue|\n","+-------+-----------+-------+--------------+\n","|Store 1|          1|    448|           448|\n","|Store 1|          2|   null|           448|\n","|Store 1|          3|    499|           499|\n","|Store 1|         44|    432|           432|\n","|   null|       null|   null|          null|\n","|Store 2|          1|    355|           355|\n","|Store 2|          1|    355|           355|\n","|Store 2|       null|    345|           345|\n","|Store 2|          3|    387|           387|\n","|Store 2|          4|    312|           312|\n","+-------+-----------+-------+--------------+\n","\n"]}],"source":["raw_df.withColumn('noNull_Revenue'\\\n","                  ,sparkf.when((sparkf.col('Store')=='Store 1')\\\n","                &(sparkf.col('Revenue').isNull()),imputed_value).otherwise(sparkf.col('Revenue'))).show()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------+-------+\n","|  Store|WeekInMonth|Revenue|\n","+-------+-----------+-------+\n","|Store 1|          1|    448|\n","|Store 1|          2|   null|\n","|Store 1|          3|    499|\n","|Store 1|         44|    432|\n","|   null|       null|   null|\n","|Store 2|          1|    355|\n","|Store 2|          1|    355|\n","|Store 2|       null|    345|\n","|Store 2|          3|    387|\n","|Store 2|          4|    312|\n","+-------+-----------+-------+\n","\n"]}],"source":["raw_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}
